# TODO - Implementar N-API para Llama.cpp Embeddings

## ğŸ¯ **Objetivo: Criar mÃ³dulo Node.js nativo com N-API para embeddings locais**

### **Contexto:**
- âŒ **HTTP API requer servidor externo**
- âœ… **N-API integra diretamente com Node.js**
- ğŸ¯ **SoluÃ§Ã£o:** MÃ³dulo nativo que carrega llama.cpp diretamente

---

## ğŸ“‹ **Plano Numerado - ImplementaÃ§Ã£o N-API**

### **1. Estrutura do Projeto N-API**
- [ ] **Criar pasta `native/`**
  - [ ] `native/binding.gyp` - ConfiguraÃ§Ã£o de build
  - [ ] `native/llama_embedding.cpp` - CÃ³digo C++ principal
  - [ ] `native/index.js` - Interface JavaScript
  - [ ] `native/package.json` - DependÃªncias especÃ­ficas

### **2. ConfiguraÃ§Ã£o de Build (binding.gyp)**
- [ ] **Definir targets**
  - [ ] Compilar cÃ³digo C++ do llama.cpp
  - [ ] Linkar com bibliotecas necessÃ¡rias
  - [ ] Configurar para mÃºltiplas plataformas
- [ ] **Include paths**
  - [ ] `../core/` - CÃ³digo do llama.cpp
  - [ ] `../core/ggml-cpu/` - ImplementaÃ§Ãµes CPU
  - [ ] Headers necessÃ¡rios

### **3. ImplementaÃ§Ã£o C++ Principal**
- [ ] **Classe LlamaEmbedding**
  - [ ] Carregar modelo GGUF
  - [ ] Inicializar contexto llama.cpp
  - [ ] MÃ©todo `embed(text)` retorna array<float>
- [ ] **IntegraÃ§Ã£o N-API**
  - [ ] `Init()` - InicializaÃ§Ã£o do mÃ³dulo
  - [ ] `CreateEmbedding()` - FunÃ§Ã£o exportada
  - [ ] Tratamento de erros e memÃ³ria

### **4. Interface JavaScript**
- [ ] **Wrapper simples**
  - [ ] `create(modelPath)` - Carrega modelo
  - [ ] `embed(text)` - Gera embedding
  - [ ] `close()` - Libera recursos
- [ ] **Error handling**
  - [ ] Try/catch para chamadas nativas
  - [ ] Mensagens de erro amigÃ¡veis
  - [ ] ValidaÃ§Ã£o de parÃ¢metros

### **5. IntegraÃ§Ã£o com Provider Existente**
- [ ] **Modificar LlamaCppProvider**
  - [ ] Importar mÃ³dulo nativo
  - [ ] Substituir chamadas HTTP
  - [ ] Manter interface atual
- [ ] **Fallback**
  - [ ] Manter HTTP como fallback
  - [ ] DetecÃ§Ã£o automÃ¡tica
  - [ ] ConfiguraÃ§Ã£o via parÃ¢metro

### **6. Build e DistribuiÃ§Ã£o**
- [ ] **Scripts de build**
  - [ ] `npm run build:native` - Compila mÃ³dulo
  - [ ] `npm run prebuild` - BinÃ¡rios prÃ©-compilados
  - [ ] IntegraÃ§Ã£o com build principal
- [ ] **Multiplataforma**
  - [ ] Linux x64
  - [ ] macOS x64/arm64
  - [ ] Windows x64

### **7. Testes e ValidaÃ§Ã£o**
- [ ] **Testes unitÃ¡rios**
  - [ ] Carregamento de modelo
  - [ ] GeraÃ§Ã£o de embedding
  - [ ] Performance vs HTTP
- [ ] **Testes de integraÃ§Ã£o**
  - [ ] Com provider atual
  - [ ] Com diferentes modelos
  - [ ] Com textos variados

### **8. DocumentaÃ§Ã£o**
- [ ] **README**
  - [ ] Como instalar dependÃªncias nativas
  - [ ] Exemplos de uso
  - [ ] Troubleshooting
- [ ] **API Documentation**
  - [ ] MÃ©todos disponÃ­veis
  - [ ] ParÃ¢metros e retorno
  - [ ] CÃ³digos de erro

---

## ğŸš€ **Status Atual**

### **âœ… ConcluÃ­do:**
- âœ… AnÃ¡lise do cÃ³digo llama.cpp completo
- âœ… Core do GGML disponÃ­vel
- âœ… Plano N-API criado

### **ğŸ”„ Em Progresso:**
- ğŸ”„ Task 1: Estrutura do projeto N-API

### **â³ PrÃ³ximos Passos:**
- â³ Criar estrutura de pastas
- â³ Configurar binding.gyp
- â³ Implementar classe C++ principal

---

## ğŸ“ **Notas TÃ©cnicas**

### **Vantagens da Abordagem N-API:**
âœ… Performance nativa (sem overhead HTTP)  
âœ… IntegraÃ§Ã£o direta com Node.js  
âœ… DistribuiÃ§Ã£o via npm  
âœ… Sem necessidade de servidor externo  
âœ… Melhor gerenciamento de memÃ³ria  

### **Estrutura Esperada:**
```
native/
â”œâ”€â”€ binding.gyp           <- ConfiguraÃ§Ã£o build
â”œâ”€â”€ llama_embedding.cpp    <- CÃ³digo C++ principal  
â”œâ”€â”€ index.js            <- Interface JS
â””â”€â”€ package.json        <- Deps especÃ­ficas
```

### **API JavaScript Esperada:**
```javascript
const llama = require('./native');

// Carrega modelo
const model = llama.create('path/to/model.gguf');

// Gera embedding
const embedding = model.embed('Hello world');

// Libera recursos
model.close();
```

### **IntegraÃ§Ã£o com Provider:**
```typescript
// Em LlamaCppProvider
import llama from '../native';

private nativeModel = llama.create(modelPath);

async embed(input: EmbedInput): Promise<EmbedResult> {
  const text = await this.readInput(input);
  const embedding = this.nativeModel.embed(text);
  return { embedding, dimensions: embedding.length, ... };
}
```

---

**PrÃ³ximo passo:** Iniciar Task 1 - Criar estrutura N-API