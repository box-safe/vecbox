# Llama.cpp Core
code taken from [llama.cpp](https://github.com/ggml-org/llama.cpp)
---
Estrutura funcional do cÃ³digo do llama.cpp para embeddings.

## ğŸ“ Estrutura

```
core/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ggml/          # Biblioteca GGML principal
â”‚   â”œâ”€â”€ llama/         # API do Llama.cpp
â”‚   â”œâ”€â”€ ggml-cpu/      # ImplementaÃ§Ãµes CPU otimizadas
â”‚   â””â”€â”€ include/       # Headers pÃºblicos
â”œâ”€â”€ CMakeLists.txt     # ConfiguraÃ§Ã£o de build
â””â”€â”€ README.md         # Este arquivo
```

## ğŸ”¨ Build

```bash
mkdir build
cd build
cmake ..
make -j$(nproc)
```

## ğŸ“¦ Biblioteca

Gera `lib/libllamacpp_core.a` estÃ¡tica para linking.

## ğŸ¯ Uso

Biblioteca base para implementaÃ§Ã£o N-API de embeddings.
